import torch
import torchvision.transforms as transforms
import torchvision.models as models
from torchvision.models import ResNet50_Weights  # –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç –≤–µ—Å–æ–≤
from aiogram import Bot, Dispatcher, types
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton
from aiogram.utils import executor
from PIL import Image
import os
import glob
import random
import rembg
import io
import time
import numpy as np
from torch import nn, optim
from torch.utils.data import DataLoader, Dataset
import asyncio

DF_COARSE_50 = [
    # –≤–µ—Ä—Ö 20
    "Anorak", "Blazer", "Blouse", "Bomber", "Button-Down",
    "Cardigan", "Flannel", "Halter", "Henley", "Hoodie",
    "Jacket", "Jersey", "Parka", "Peacoat", "Poncho",
    "Sweater", "Tank", "Tee", "Top", "Turtleneck",
    # –Ω–∏–∑ 15
    "Capris", "Chinos", "Culottes", "Cutoffs", "Gauchos",
    "Jeans", "Jeggings", "Jodhpurs", "Joggers", "Leggings",
    "Sarong", "Shorts", "Skirt", "Sweatshorts", "Trunks",
    # full-body 15
    "Caftan", "Cape", "Coat", "Coverup", "Dress",
    "Jumpsuit", "Kaftan", "Kimono", "Nightdress", "Onesie",
    "Robe", "Romper", "Shirtdress", "Sundress", "Slacks"   # Slacks = 50-–π
]

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
TOKEN = "7803258791:AAE1sFkqfQyQjeea-E1TImzCI4z6d9B5xuk"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
bot = Bot(token=TOKEN)
dp = Dispatcher(bot)

# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –æ–¥–µ–∂–¥—ã
# def load_category_names(category_file="deepfashion/Anno_coarse/list_category_cloth.txt"):
#     with open(category_file, "r") as f:
#         return [line.split()[0] for line in f.readlines()[2:]]
def load_category_names(category_file="deepfashion/Anno_coarse/list_category_cloth.txt"):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –æ–¥–µ–∂–¥—ã.
    ‚Ä¢ –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ txt-—Ñ–∞–π–ª–∞ –Ω–µ—Ç ‚Äî –±–µ—Ä—ë–º –∏–º–µ–Ω–∞ –ø–æ–¥–ø–∞–ø–æ–∫ images/*,
      –∞ –ø—Ä–∏ –∏—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ ‚Äî –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ DF_COARSE_50.
    """
#     # 1. –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª DeepFashion
#     if os.path.exists(category_file):
#         with open(category_file, "r") as f:
#             # —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ 2 —Å—Ç—Ä–æ–∫ ‚Üí –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
#             return [line.split()[0] for line in f.readlines()[2:]]
#
#     # 2. –§–∞–π–ª –ø–æ—Ç–µ—Ä—è–Ω ‚Üí –ø—Ä–æ–±—É–µ–º –ø–æ–¥–∫–∞—Ç–∞–ª–æ–≥–∏ images/*
#     image_root = "images"
#     if os.path.isdir(image_root):
#         subdirs = sorted(
#             d for d in os.listdir(image_root)
#             if os.path.isdir(os.path.join(image_root, d))
#         )
#         if subdirs:                             # –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ —Ö–æ—Ç—å —á—Ç–æ-—Ç–æ
#             return subdirs
#
#     # 3. –í –∫–∞—Ç–∞–ª–æ–≥–µ images –ø—É—Å—Ç–æ ‚Üí –±–µ—Ä—ë–º –∂—ë—Å—Ç–∫–æ –ø—Ä–æ—à–∏—Ç—ã–π —Å–ø–∏—Å–æ–∫
    return DF_COARSE_50

categories = load_category_names()


# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∞–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ API torchvision
def initialize_model():
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–π —Å–ø–æ—Å–æ–± –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏
    weights = ResNet50_Weights.IMAGENET1K_V1
    model = models.resnet50(weights=weights)

    # –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –≤—Å–µ —Å–ª–æ–∏ –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ
    for param in model.parameters():
        param.requires_grad = False
    model.fc = nn.Linear(model.fc.in_features, len(categories))
    model.fc.requires_grad = True

    if os.path.exists("deepfashion_resnet50.pth"):
        model.load_state_dict(torch.load("deepfashion_resnet50.pth", map_location=DEVICE))

    return model.to(DEVICE)

model = initialize_model()

# –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
train_transform = transforms.Compose([
    # transforms.RandomHorizontalFlip(),
    # transforms.ColorJitter(0.1, 0.1, 0.1),
    # transforms.Resize(256),
    # transforms.RandomCrop(224),
    # transforms.ToTensor(),
    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    transforms.Resize(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

val_transform = transforms.Compose([
    transforms.Resize(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
for category in categories:
    os.makedirs(f"images/{category}", exist_ok=True)
os.makedirs("temp", exist_ok=True)

def process_image(image: Image.Image) -> Image.Image:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —É–¥–∞–ª–µ–Ω–∏–µ–º —Ñ–æ–Ω–∞"""
    output = rembg.remove(image)
    img = Image.open(io.BytesIO(output)).convert("RGBA")
    white_bg = Image.new("RGBA", img.size, (255, 255, 255, 255))
    return Image.alpha_composite(white_bg, img).convert("RGB")

def remove_background(image: Image.Image) -> Image.Image:
    """–£–¥–∞–ª–µ–Ω–∏–µ —Ñ–æ–Ω–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∑–∞–º–µ–Ω–æ–π –Ω–∞ –±–µ–ª—ã–π"""
    try:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –±–∞–π—Ç—ã
        img_byte_arr = io.BytesIO()
        image.save(img_byte_arr, format='PNG')
        img_bytes = img_byte_arr.getvalue()

        # –£–¥–∞–ª—è–µ–º —Ñ–æ–Ω
        output_bytes = rembg.remove(img_bytes)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        output_img = Image.open(io.BytesIO(output_bytes)).convert("RGBA")

        # –°–æ–∑–¥–∞–µ–º –±–µ–ª—ã–π —Ñ–æ–Ω
        white_bg = Image.new("RGBA", output_img.size, (255, 255, 255, 255))
        result_img = Image.alpha_composite(white_bg, output_img).convert("RGB")

        return result_img
    except Exception as e:
        print(f"Error in remove_background: {str(e)}")
        return image  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏

def classify_image(image: Image.Image) -> str:
    """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    model.eval()
    tensor = val_transform(image).unsqueeze(0).to(DEVICE)
    with torch.no_grad():
        outputs = model(tensor)
        _, pred = torch.max(outputs, 1)
    return categories[pred.item()]

class BalanceDataset(Dataset):
    """–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è"""
    def __init__(self, new_image, category, old_ratio=0.3):
        self.new_image = new_image
        self.category_idx = categories.index(category)
        self.old_images = self._load_old_images(category, old_ratio)

    def _load_old_images(self, category, ratio):
        files = glob.glob(f"images/{category}/*.jpg")
        if not files: return []
        selected = np.random.choice(files, size=int(len(files)*ratio), replace=False)
        return [Image.open(f).convert("RGB") for f in selected]

    def __len__(self): return 64

    def __getitem__(self, idx):
        img = self.new_image if idx % 2 == 0 or not self.old_images else random.choice(self.old_images)
        return train_transform(img), torch.tensor(self.category_idx)

def safe_fine_tune(model, new_image, category):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –¥–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    model.train()
    dataset = BalanceDataset(new_image, category)
    loader = DataLoader(dataset, batch_size=16, shuffle=True)

    optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)
    criterion = nn.CrossEntropyLoss()

    for _ in range(3):  # 2 —ç–ø–æ—Ö–∏
        for inputs, labels in loader:
            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.fc.parameters(), 1.0)
            optimizer.step()

    model.eval()
    torch.save(model.state_dict(), "deepfashion_resnet50.pth")
    return model

# –•—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
user_data = {}
keyboard = ReplyKeyboardMarkup(resize_keyboard=True).add(
    KeyboardButton("–°–æ–±—Ä–∞—Ç—å –æ–±—Ä–∞–∑"),
    KeyboardButton("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≥–∞—Ä–¥–µ—Ä–æ–±"),
    KeyboardButton("–û—á–∏—Å—Ç–∏—Ç—å –≥–∞—Ä–¥–µ—Ä–æ–±")
)

@dp.message_handler(commands=['start'])
async def start(message: types.Message):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start"""
    model.load_state_dict(torch.load("deepfashion_resnet50.pth", map_location=DEVICE))
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –ó–∞–≥—Ä—É–∑–∏ —Ñ–æ—Ç–æ –æ–¥–µ–∂–¥—ã, –∏ —è –æ–ø—Ä–µ–¥–µ–ª—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é.", reply_markup=keyboard)

# –î–æ–±–∞–≤–ª—è–µ–º –≤ –Ω–∞—á–∞–ª–æ –∫–æ–¥–∞ (–ø–æ—Å–ª–µ user_data)
user_stacks = {}  # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç–µ–∫–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π

def get_user_stack(user_id):
    """–ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º —Å—Ç–µ–∫ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    if user_id not in user_stacks:
        user_stacks[user_id] = []
    return user_stacks[user_id]

# –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ñ–æ—Ç–æ
@dp.message_handler(content_types=['photo'])
async def handle_photo(message: types.Message):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–æ—Ç–æ"""
    try:
        user_id = message.from_user.id
        file_id = message.photo[-1].file_id

        # –î–æ–±–∞–≤–ª—è–µ–º file_id –≤ —Å—Ç–µ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_stack = get_user_stack(user_id)
        user_stack.append(file_id)

        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–æ—Ç–æ
        file = await message.photo[-1].get_file()
        img_path = f"temp/{file_id}.jpg"
        await file.download(img_path)

        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image = Image.open(img_path).convert("RGB")
        processed_image = remove_background(image)

        # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        category = classify_image(processed_image)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
        user_data[file_id] = {
            'image': processed_image,
            'category': category,
            'path': img_path,
            'user_id': user_id
        }

        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
        markup = ReplyKeyboardMarkup(resize_keyboard=True)
        markup.add("–î–∞", "–ù–µ—Ç")
        await message.answer(f"–≠—Ç–æ {category}?", reply_markup=markup)

    except Exception as e:
        await message.answer(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–æ—Ç–æ: {str(e)}")
        print(f"Error in handle_photo: {str(e)}")

# –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
@dp.message_handler(lambda m: m.text in ["–î–∞", "–ù–µ—Ç"])
async def handle_confirmation(message: types.Message):
    user_id = message.from_user.id
    user_stack = get_user_stack(user_id)

    if message.text == "–î–∞":
        if not user_stack:
            return await message.answer("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ñ–æ—Ç–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏!")

        file_id = user_stack.pop()  # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Ñ–æ—Ç–æ –∏–∑ —Å—Ç–µ–∫–∞
        data = user_data.get(file_id)

        if not data:
            return await message.answer("–î–∞–Ω–Ω—ã–µ —Ñ–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")

        category = data['category']
        save_path = f"images/{category}/{int(time.time())}.jpg"
        data['image'].save(save_path)
        # global model
        # model = safe_fine_tune(model, data['image'], category)
        await message.answer("–ú–æ–¥–µ–ª—å –æ–±–Ω–æ–≤–ª–µ–Ω–∞! ‚úÖ", reply_markup=keyboard)
    else:
        markup = ReplyKeyboardMarkup(resize_keyboard=True)
        markup.add(*categories)
        await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—é:", reply_markup=markup)

    # –ù–µ —É–¥–∞–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ —Å—Ä–∞–∑—É, –æ–Ω–∏ –º–æ–≥—É—Ç –ø–æ–Ω–∞–¥–æ–±–∏—Ç—å—Å—è –¥–ª—è –≤—ã–±–æ—Ä–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    # –û—á–∏—Å—Ç–∫–∞ –±—É–¥–µ—Ç –ø–æ—Å–ª–µ –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è

@dp.message_handler(lambda message: message.text in categories)
async def handle_category_selection(message: types.Message):
    user_id = message.from_user.id
    user_stack = get_user_stack(user_id)

    if not user_stack:
        return await message.answer("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ñ–æ—Ç–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏!")

    file_id = user_stack[-1]  # –ë–µ—Ä–µ–º —Ç–µ–∫—É—â–µ–µ —Ñ–æ—Ç–æ (–Ω–µ —É–¥–∞–ª—è–µ–º –∏–∑ —Å—Ç–µ–∫–∞)
    data = user_data.get(file_id)

    if not data:
        return await message.answer("–î–∞–Ω–Ω—ã–µ —Ñ–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")

    category = message.text
    save_path = f"images/{category}/{int(time.time())}.jpg"
    data['image'].save(save_path)

    global model
    model = safe_fine_tune(model, data['image'], category)

    # –£–¥–∞–ª—è–µ–º —Ñ–æ—Ç–æ –∏–∑ —Å—Ç–µ–∫–∞ –∏ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    user_stack.pop()
    del user_data[file_id]

    await message.answer(f"–§–æ—Ç–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {category}! ‚úÖ", reply_markup=keyboard)


@dp.message_handler(lambda message: message.text == "–°–æ–±—Ä–∞—Ç—å –æ–±—Ä–∞–∑")
async def assemble_outfit(message: types.Message):
    try:
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≤—Å–µ—Ö 50 –∫–ª–∞—Å—Å–æ–≤ DeepFashion
        WARM_TOPS = ["Anorak", "Bomber", "Cardigan", "Flannel", "Hoodie",
                    "Jacket", "Parka", "Peacoat", "Poncho", "Sweater", "Turtleneck"]
        FORMAL_TOPS = ["Blazer", "Blouse", "Button-Down", "Shirtdress"]
        SPORT_TOPS = ["Jersey", "Tank", "Halter", "Top"]
        CASUAL_TOPS = ["Tee", "Henley", "Polo"]
        FULL_BODY = ["Dress", "Jumpsuit", "Romper", "Caftan", "Cape",
                    "Coverup", "Kaftan", "Kimono", "Nightdress", "Onesie",
                    "Robe", "Sundress"]

        SPORT_BOTTOMS = ["Joggers", "Leggings", "Sweatpants", "Sweatshorts", "Trunks"]
        FORMAL_BOTTOMS = ["Chinos", "Slacks"]
        CASUAL_BOTTOMS = ["Jeans", "Jeggings", "Capris", "Culottes", "Cutoffs",
                         "Gauchos", "Jodhpurs", "Sarong", "Shorts", "Skirt"]

        # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∞–π–ª—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        def gather_files(categories):
            files = []
            for cat in categories:
                cat_files = glob.glob(f"images/{cat}/*.jpg") + glob.glob(f"images/{cat}/*.png")
                files.extend(cat_files)
            return files

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –≤–µ—â–∏
        warm_tops = gather_files(WARM_TOPS)
        formal_tops = gather_files(FORMAL_TOPS)
        sport_tops = gather_files(SPORT_TOPS)
        casual_tops = gather_files(CASUAL_TOPS)
        full_body = gather_files(FULL_BODY)

        sport_bottoms = gather_files(SPORT_BOTTOMS)
        formal_bottoms = gather_files(FORMAL_BOTTOMS)
        casual_bottoms = gather_files(CASUAL_BOTTOMS)

        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º full body - –æ–Ω–∏ –Ω–µ —Ç—Ä–µ–±—É—é—Ç –ø–∞—Ä—ã
        if full_body and random.random() < 0.3:  # 30% chance –≤—ã–±—Ä–∞—Ç—å full body
            selected_item = random.choice(full_body)
            collage = Image.new('RGB', (256, 512))
            img = Image.open(selected_item).resize((256, 512))
            collage.paste(img, (0, 0))
        else:
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –≤–µ—Ä—Ö–∏ —Å –∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
            top_options = []
            if warm_tops: top_options.extend([("warm", top) for top in warm_tops])
            if formal_tops: top_options.extend([("formal", top) for top in formal_tops])
            if sport_tops: top_options.extend([("sport", top) for top in sport_tops])
            if casual_tops: top_options.extend([("casual", top) for top in casual_tops])

            if not top_options:
                return await message.answer("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≤–µ—Ä—Ö–Ω–∏—Ö –≤–µ—â–µ–π üò¢")

            # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤–µ—Ä—Ö–æ–≤ –¥–ª—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞
            random.shuffle(top_options)

            # –§–ª–∞–≥, —á—Ç–æ –æ–±—Ä–∞–∑ —Å–æ–±—Ä–∞–Ω
            outfit_assembled = False

            for top_category, selected_top in top_options:
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–¥–æ–±—Ä–∞—Ç—å –Ω–∏–∑ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –≤–µ—Ä—Ö–∞
                bottom_options = []

                # 1. –¢–µ–ø–ª—ã–π –≤–µ—Ä—Ö (–Ω–µ —Å–æ—á–µ—Ç–∞–µ—Ç—Å—è —Å —à–æ—Ä—Ç–∞–º–∏ –∏ —Å–ø–æ—Ä—Ç–∏–≤–Ω—ã–º–∏ –Ω–∏–∑–∞–º–∏)
                if top_category == "warm":
                    bottom_options.extend(formal_bottoms)
                    bottom_options.extend([b for b in casual_bottoms
                                        if not any(x in b for x in ["Shorts", "Cutoffs", "Trunks"])])

                # 2. –§–æ—Ä–º–∞–ª—å–Ω—ã–π –≤–µ—Ä—Ö (—Ç–æ–ª—å–∫–æ —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–µ/–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –Ω–∏–∑—ã)
                elif top_category == "formal":
                    bottom_options.extend(formal_bottoms)
                    bottom_options.extend([b for b in casual_bottoms
                                         if not any(x in b for x in ["Shorts", "Sweatshorts", "Cutoffs"])])

                # 3. –°–ø–æ—Ä—Ç–∏–≤–Ω—ã–π –≤–µ—Ä—Ö (—Ç–æ–ª—å–∫–æ —Å–ø–æ—Ä—Ç–∏–≤–Ω—ã–µ –Ω–∏–∑—ã –∏ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ casual)
                elif top_category == "sport":
                    bottom_options.extend(sport_bottoms)
                    bottom_options.extend([b for b in casual_bottoms
                                         if any(x in b for x in ["Shorts", "Sweatshorts", "Joggers"])])

                # 4. Casual –≤–µ—Ä—Ö (–ø–æ—á—Ç–∏ –ª—é–±—ã–µ –Ω–∏–∑—ã, –∫—Ä–æ–º–µ —è–≤–Ω–æ –Ω–µ—Å–æ—á–µ—Ç–∞–µ–º—ã—Ö)
                elif top_category == "casual":
                    bottom_options.extend(casual_bottoms)
                    if "Tee" not in selected_top:  # –ï—Å–ª–∏ –Ω–µ –ø—Ä–æ—Å—Ç–∞—è —Ñ—É—Ç–±–æ–ª–∫–∞
                        bottom_options.extend(formal_bottoms)
                    bottom_options.extend([b for b in sport_bottoms
                                         if any(x in b for x in ["Shorts", "Sweatshorts"])])

                # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                bottom_options = list(set(bottom_options))

                if bottom_options:
                    # –ù–∞—à–ª–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –Ω–∏–∑—ã - —Å–æ–±–∏—Ä–∞–µ–º –æ–±—Ä–∞–∑
                    selected_bottom = random.choice(bottom_options)
                    outfit_assembled = True
                    break

            if not outfit_assembled:
                return await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –æ–±—Ä–∞–∑ –∏–∑ –∏–º–µ—é—â–∏—Ö—Å—è –≤–µ—â–µ–π üò¢")

            # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–ª–∞–∂ (–≤–µ—Ä—Ö + –Ω–∏–∑)
            collage = Image.new('RGB', (256, 512))
            collage.paste(Image.open(selected_top).resize((256, 256)), (0, 0))
            collage.paste(Image.open(selected_bottom).resize((256, 256)), (0, 256))

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        timestamp = int(time.time())
        collage_path = f"temp/outfit_{timestamp}.jpg"
        os.makedirs("temp", exist_ok=True)
        collage.save(collage_path)

        with open(collage_path, 'rb') as photo:
            await message.answer_photo(photo, caption="–í–∞—à —Å—Ç–∏–ª—å–Ω—ã–π –æ–±—Ä–∞–∑!")

        os.remove(collage_path)

    except FileNotFoundError as e:
        logger.error(f"File not found: {e}")
        await message.answer("–û—à–∏–±–∫–∞: –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ–∞–π–ª—ã –æ–¥–µ–∂–¥—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    except PIL.UnidentifiedImageError:
        await message.answer("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –æ–±—Ä–∞–∑–∞: {e}")
        await message.answer("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –æ–±—Ä–∞–∑–∞ üò¢")

@dp.message_handler(lambda message: message.text == "–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≥–∞—Ä–¥–µ—Ä–æ–±")
async def view_closet(message: types.Message):
    try:
        for category in categories:
            files = glob.glob(f"images/{category}/*.jpg")
            if not files: continue

            await message.answer(f"üìÅ {category}:")
            for file in files[:3]:
                with open(file, 'rb') as photo:
                    await message.answer_photo(photo)
                    await asyncio.sleep(0.3)
    except Exception as e:
        await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ üò¢")

@dp.message_handler(lambda message: message.text == "–û—á–∏—Å—Ç–∏—Ç—å –≥–∞—Ä–¥–µ—Ä–æ–±")
async def clear_closet(message: types.Message):
    markup = ReplyKeyboardMarkup(resize_keyboard=True)
    markup.add("–ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å –æ—á–∏—Å—Ç–∫—É", "–û—Ç–º–µ–Ω–∞")
    await message.answer("–í—ã —É–≤–µ—Ä–µ–Ω—ã? –≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏–µ –Ω–µ–æ–±—Ä–∞—Ç–∏–º–æ!", reply_markup=markup)

@dp.message_handler(lambda message: message.text == "–ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å –æ—á–∏—Å—Ç–∫—É")
async def confirm_clear(message: types.Message):
    count = 0
    for category in categories:
        files = glob.glob(f"images/{category}/*.jpg")
        for file in files:
            os.remove(file)
            count += 1
    await message.answer(f"–£–¥–∞–ª–µ–Ω–æ {count} –ø—Ä–µ–¥–º–µ—Ç–æ–≤! üóëÔ∏è", reply_markup=keyboard)

@dp.message_handler(lambda message: message.text == "–û—Ç–º–µ–Ω–∞")
async def cancel_clear(message: types.Message):
    await message.answer("–û—á–∏—Å—Ç–∫–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞ ‚úÖ", reply_markup=keyboard)

async def on_startup(_):
    """–î–µ–π—Å—Ç–≤–∏—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –±–æ—Ç–∞"""
    await bot.set_my_commands([
        types.BotCommand(command="/start", description="–ó–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞")
    ])

if __name__ == "__main__":
    executor.start_polling(dp, skip_updates=True, on_startup=on_startup)
